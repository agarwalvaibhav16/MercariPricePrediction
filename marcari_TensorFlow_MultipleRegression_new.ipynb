{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MULTIPLE REGRESSION IN TENSOR FLOW:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from nltk.tokenize import LineTokenizer, SpaceTokenizer, TweetTokenizer\n",
    "from nltk import word_tokenize\n",
    "from nltk import word_tokenize, PorterStemmer, WordNetLemmatizer\n",
    "import string\n",
    "import matplotlib\n",
    "import re\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn import preprocessing as skpp\n",
    "from sklearn.model_selection import train_test_split \n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_miss_50000=pd.read_pickle('/Users/Desktop/df_50000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>sub_cat1</th>\n",
       "      <th>sub_cat2</th>\n",
       "      <th>sub_cat3</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Size</th>\n",
       "      <th>MostCommonWord</th>\n",
       "      <th>brand_prediction</th>\n",
       "      <th>confidence_level</th>\n",
       "      <th>brand_name_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>MLB</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>Men</td>\n",
       "      <td>Tops</td>\n",
       "      <td>T-shirts</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL Men Tops T...</td>\n",
       "      <td>[mlb, cincinnati, red, shirt, size, xl, men, t...</td>\n",
       "      <td>[XL]</td>\n",
       "      <td>mlb</td>\n",
       "      <td>[(1, MLB)]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>MLB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>iHome</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home Décor</td>\n",
       "      <td>Home Décor Accents</td>\n",
       "      <td>Leather Horse Statues Home Home Décor Home Déc...</td>\n",
       "      <td>[leather, horse, statue, home, home, décor, ho...</td>\n",
       "      <td>[]</td>\n",
       "      <td>home</td>\n",
       "      <td>[(0.8, iHome)]</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>iHome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "      <td>Women</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>Necklaces</td>\n",
       "      <td>24K GOLD plated rose Women Jewelry Necklaces n...</td>\n",
       "      <td>[24k, gold, plated, rose, woman, jewelry, neck...</td>\n",
       "      <td>[]</td>\n",
       "      <td>24k</td>\n",
       "      <td>[(0.09999999999999998, 24/7 Comfort Apparel)]</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>24/7 Comfort Apparel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Bundled items requested for Ruie</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Other/Other</td>\n",
       "      <td>TomTom</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Banana republic bottoms, Candies skirt with ma...</td>\n",
       "      <td>Women</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Bundled items requested for Ruie Women Other O...</td>\n",
       "      <td>[bundled, item, requested, ruie, woman, nan, b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>bottom</td>\n",
       "      <td>[(0.6666666666666667, TomTom), (0.666666666666...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>TomTom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Porcelain clown doll checker pants VTG</td>\n",
       "      <td>3</td>\n",
       "      <td>Vintage &amp; Collectibles/Collectibles/Doll</td>\n",
       "      <td>Lowa</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>I realized his pants are on backwards after th...</td>\n",
       "      <td>Vintage &amp; Collectibles</td>\n",
       "      <td>Collectibles</td>\n",
       "      <td>Doll</td>\n",
       "      <td>Porcelain clown doll checker pants VTG Vintage...</td>\n",
       "      <td>[porcelain, clown, doll, checker, pant, vtg, v...</td>\n",
       "      <td>[]</td>\n",
       "      <td>clown</td>\n",
       "      <td>[(0.6, Lowa), (0.6, CLEAN)]</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Lowa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                    name  item_condition_id  \\\n",
       "0         0     MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "3         3                   Leather Horse Statues                  1   \n",
       "4         4                    24K GOLD plated rose                  1   \n",
       "5         5        Bundled items requested for Ruie                  3   \n",
       "9         9  Porcelain clown doll checker pants VTG                  3   \n",
       "\n",
       "                              category_name brand_name  price  shipping  \\\n",
       "0                         Men/Tops/T-shirts        MLB   10.0         1   \n",
       "3        Home/Home Décor/Home Décor Accents      iHome   35.0         1   \n",
       "4                   Women/Jewelry/Necklaces        NaN   44.0         0   \n",
       "5                         Women/Other/Other     TomTom   59.0         0   \n",
       "9  Vintage & Collectibles/Collectibles/Doll       Lowa    8.0         0   \n",
       "\n",
       "                                    item_description                sub_cat1  \\\n",
       "0                                 No description yet                     Men   \n",
       "3  New with tags. Leather horses. Retail for [rm]...                    Home   \n",
       "4          Complete with certificate of authenticity                   Women   \n",
       "5  Banana republic bottoms, Candies skirt with ma...                   Women   \n",
       "9  I realized his pants are on backwards after th...  Vintage & Collectibles   \n",
       "\n",
       "       sub_cat2            sub_cat3  \\\n",
       "0          Tops            T-shirts   \n",
       "3    Home Décor  Home Décor Accents   \n",
       "4       Jewelry           Necklaces   \n",
       "5         Other               Other   \n",
       "9  Collectibles                Doll   \n",
       "\n",
       "                                                text  \\\n",
       "0  MLB Cincinnati Reds T Shirt Size XL Men Tops T...   \n",
       "3  Leather Horse Statues Home Home Décor Home Déc...   \n",
       "4  24K GOLD plated rose Women Jewelry Necklaces n...   \n",
       "5  Bundled items requested for Ruie Women Other O...   \n",
       "9  Porcelain clown doll checker pants VTG Vintage...   \n",
       "\n",
       "                                              tokens  Size MostCommonWord  \\\n",
       "0  [mlb, cincinnati, red, shirt, size, xl, men, t...  [XL]            mlb   \n",
       "3  [leather, horse, statue, home, home, décor, ho...    []           home   \n",
       "4  [24k, gold, plated, rose, woman, jewelry, neck...    []            24k   \n",
       "5  [bundled, item, requested, ruie, woman, nan, b...    []         bottom   \n",
       "9  [porcelain, clown, doll, checker, pant, vtg, v...    []          clown   \n",
       "\n",
       "                                    brand_prediction  confidence_level  \\\n",
       "0                                         [(1, MLB)]          1.000000   \n",
       "3                                     [(0.8, iHome)]          0.800000   \n",
       "4      [(0.09999999999999998, 24/7 Comfort Apparel)]          0.100000   \n",
       "5  [(0.6666666666666667, TomTom), (0.666666666666...          0.666667   \n",
       "9                        [(0.6, Lowa), (0.6, CLEAN)]          0.600000   \n",
       "\n",
       "   brand_name_predicted  \n",
       "0                   MLB  \n",
       "3                 iHome  \n",
       "4  24/7 Comfort Apparel  \n",
       "5                TomTom  \n",
       "9                  Lowa  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_miss_50000.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "    \n",
    "\n",
    "X_cat1 = vectorizer.fit_transform(df_miss_50000['sub_cat1'])\n",
    "X_cat2 = vectorizer.fit_transform(df_miss_50000['sub_cat2'])\n",
    "# X_cat3 = vectorizer.fit_transform(df_miss_50000['sub_cat3'])\n",
    "# X_item = vectorizer.fit_transform(df_miss_50000['item_description'])\n",
    "X_most_common_word=vectorizer.fit_transform(df_miss_50000['MostCommonWord'])\n",
    "X_dummies = csr_matrix(pd.get_dummies(df_miss_50000[['item_condition_id', 'shipping']],sparse=True).values)\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "# sparse_merge = hstack((X_cat1, X_cat2,X_cat3,X_item,X_most_common_word,X_dummies)).tocsr()\n",
    "sparse_merge = hstack((X_cat1,X_cat2, X_most_common_word,X_dummies)).tocsr()\n",
    "\n",
    "sparse_merge=csr_matrix(sparse_merge.shape, dtype=np.float32).toarray()\n",
    "\n",
    "\n",
    "\n",
    "## reduced the number of categries becoz of slow processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sparse_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[10.],\n",
       "       [35.],\n",
       "       [44.],\n",
       "       ...,\n",
       "       [ 8.],\n",
       "       [53.],\n",
       "       [ 8.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df_miss_50000['price'].astype(np.float32)  ##y is the price to be predicted.\n",
    "y.ndim\n",
    "y=y.values.reshape(len(y),1)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 5779)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "5779"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=123)\n",
    "num_outputs = y_train.shape[1] \n",
    "num_inputs = X_train.shape[1]\n",
    "X_train.shape\n",
    "num_inputs\n",
    "num_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 5779)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(30000, 5779)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "type(X_train)\n",
    "# X_train=X_train.todense()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 5779)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(30000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = tf.placeholder(dtype=tf.float32, \n",
    "    shape=[None, num_inputs], name=\"x\") \n",
    "y_tensor = tf.placeholder(dtype=tf.float32, \n",
    "    shape=[None, num_outputs], name=\"y\") \n",
    "\n",
    "w = tf.Variable(tf.zeros([num_inputs,num_outputs]), \n",
    "    dtype=tf.float32, name=\"w\") \n",
    "b = tf.Variable(tf.zeros([num_outputs]), \n",
    "    dtype=tf.float32, name=\"b\") \n",
    "\n",
    "model = tf.matmul(x_tensor, w) + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(model - y_tensor))\n",
    "# mse and R2 functions\n",
    "mse = tf.reduce_mean(tf.square(model - y_tensor))\n",
    "y_mean = tf.reduce_mean(y_tensor)\n",
    "total_error = tf.reduce_sum(tf.square(y_tensor - y_mean))\n",
    "unexplained_error = tf.reduce_sum(tf.square(y_tensor - model))\n",
    "rs = 1 - tf.div(unexplained_error, total_error)\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "num_epochs = 1500\n",
    "loss_epochs = np.empty(shape=[num_epochs],dtype=np.float32)\n",
    "mse_epochs = np.empty(shape=[num_epochs],dtype=np.float32)\n",
    "rs_epochs = np.empty(shape=[num_epochs],dtype=np.float32)\n",
    "\n",
    "mse_score = 0\n",
    "rs_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test data : MSE = 634.16931152, R2 = -0.00169790 \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        feed_dict = {x_tensor: X_train, y_tensor: y_train}\n",
    "        loss_val, _ = tfs.run([loss, optimizer], feed_dict)\n",
    "        loss_epochs[epoch] = loss_val\n",
    "\n",
    "\n",
    "        mse_score, rs_score = tfs.run([mse, rs], feed_dict)\n",
    "        mse_epochs[epoch] = mse_score\n",
    "        rs_epochs[epoch] = rs_score\n",
    "\n",
    "print('For test data : MSE = {0:.8f}, R2 = {1:.8f} '.format(\n",
    "    mse_score, rs_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracy is low for this model as well.\n",
    "We need to optimize the model for better accuracy.\n",
    "Maybe by changing the number of features or the kind of features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
